{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "'''Validation the per-locus ABC method'''\n",
    "\n",
    "%pylab inline\n",
    "import sys\n",
    "sys.path.append(\"/storage/BonnieH/selection_project/helper_functions\")\n",
    "from LRT_functions import *\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import time\n",
    "PLOTDIR = '/storage/BonnieH/selection_project/validation_per_locus/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot validation figures\n",
    "def plot_figure(fig_num, per, opt_allele_list, est_s_dic, errors, s_vals, use_het, use_common, use_bins, num_bins, eps_bins, model, graph_type):\n",
    "    \n",
    "    plt.figure(fig_num)\n",
    "    for opt_allele in opt_allele_list:\n",
    "            \n",
    "        if len(opt_allele_list) == 1:\n",
    "            plt.errorbar(s_vals, est_s_dic[opt_allele], marker = 'o', label = str(opt_allele), yerr = errors[opt_allele])\n",
    "            \n",
    "        else:\n",
    "            plt.errorbar(s_vals, est_s_dic[opt_allele], marker = 'o', label = str(opt_allele))\n",
    "    \n",
    "    if graph_type == 'abc':\n",
    "        plt.plot( [10**-6,0.2],[10**-6,0.2] )\n",
    "        plt.ylabel(\"Posterior estimation of s\", size=15) \n",
    "        titlename = 'ABC Validation Per ' + str(per)\n",
    "        filename = PLOTDIR + 'ABC/per' + str(per)\n",
    "        plt.yscale('log')\n",
    "        \n",
    "    if graph_type == 'lrt':\n",
    "        plt.ylabel(\"Power\", size=15) # -$log_{10}$(P value)\n",
    "        titlename = 'LRT Validation Per ' + str(per)\n",
    "        filename = PLOTDIR + 'LRT/power/per' + str(per)\n",
    "    \n",
    "    plt.xlabel(\"S value used for simulation\", size=15)\n",
    "    plt.xscale('log')\n",
    "    plt.xlim(10**-6.5,0.3)\n",
    "    plt.legend()\n",
    "   \n",
    "    opt_allele_string = '_'\n",
    "    for opt_allele in opt_allele_list:\n",
    "        opt_allele_string = opt_allele_string + str(opt_allele)\n",
    "    filename = filename + opt_allele_string\n",
    "    titlename = titlename + '\\nSummary statistics used: '\n",
    "    if use_het == 'y':\n",
    "        filename = filename + '_het'\n",
    "        titlename = titlename + 'Heterozygosity '\n",
    "    if use_common == 'y':\n",
    "        filename = filename + '_common'\n",
    "        titlename = titlename + 'Number_Common_Alleles '\n",
    "    if use_bins == 'y':\n",
    "        filename = filename + '_' + str(num_bins) + 'bins' + '_' + str(eps_bins) \n",
    "        titlename = titlename + str(num_bins) + '_Allele_Bins '\n",
    "    \n",
    "    filename = filename + '_' + model[-2:]+ '.pdf'\n",
    "    titlename = titlename + '\\nPrior number ' + model[-1:]\n",
    "    plt.title(titlename, size=15)\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    print('Done figure ' + str(fig_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate ABC and LRT\n",
    "def validate(per, opt_allele, s_vals, use_het, use_common, use_bins, num_bins, model, fig_num):\n",
    "    \n",
    "    # Process list of optimal alleles\n",
    "    opt_allele_list = list(opt_allele.split(','))\n",
    "    opt_allele_list = list(map(int, opt_allele_list)) \n",
    "    \n",
    "    # Process list of s values\n",
    "    s_vals = list(s_vals.split(','))\n",
    "    s_vals = list(map(float, s_vals))\n",
    "    \n",
    "    # ABC parameters\n",
    "    constant_het = 0.005\n",
    "    denom_het = 3\n",
    "    constant_common = 1\n",
    "    denom_common = 4\n",
    "    eps_bins = 0.3\n",
    "    \n",
    "    # LRT parameters\n",
    "    LRT_num_sims = 200\n",
    "         \n",
    "    # Each dictionary contains values for all optimal alleles\n",
    "    # Key: optimal allele\n",
    "    # Value: list of mean values for each s \n",
    "    s_vals_dic = {}\n",
    "    errors_s_dic = {}\n",
    "    p_vals_dic = {}\n",
    "    errors_p_dic = {}\n",
    "    \n",
    "    # Initialize dictionaries above\n",
    "    for opt_allele in opt_allele_list:\n",
    "        s_vals_dic[opt_allele] = []\n",
    "        errors_s_dic[opt_allele] = []\n",
    "        p_vals_dic[opt_allele] = []\n",
    "        errors_p_dic[opt_allele] = []\n",
    "      \n",
    "    # Run ABC and LRT for each opt_allele\n",
    "    for opt_allele in opt_allele_list:\n",
    "        \n",
    "        print('Running per: ' + str(per) + ' optimal allele: ' + str(opt_allele))\n",
    "        no_ABC_accept = 0 # Number of s values with <10 ABC acceptances\n",
    "        \n",
    "        ### Get list of s values in LRT simulations file ###\n",
    "        s_list_available = []\n",
    "        lrtFile = '/gymreklab-tscc/bonnieh/lrt/results/' + 'euro_prelim' + '/' + str(per) + '_' + str(opt_allele) + '_freqs.txt'\n",
    "        lrt_file = open(lrtFile, 'r')\n",
    "        header = lrt_file.readline().strip()\n",
    "    \n",
    "        for line in lrt_file:\n",
    "            info = line.strip().split('\\t')\n",
    "            s = float(info[0])\n",
    "            if s not in s_list_available:\n",
    "                s_list_available.append(s)\n",
    "            \n",
    "        est_s_dic = {} # Dictionary of estimated s values; Key: True value of s, Value: list of estimated s values\n",
    "        \n",
    "        # Put summary statistics in dictionaries\n",
    "        obs_het_dic = {} # Key - s; value - list of het\n",
    "        obs_comm_dic = {} # Key - s; value - list of number of common alleles (frequency >= 5%)\n",
    "        obs_bins_dic = {} # Key - s; value - list of bins (bins are given as lists)\n",
    "        \n",
    "        # Same as dictionaries above except without simulations \n",
    "        # where s could not be estimated using ABC (<10 ABC acceptances)\n",
    "        # These are the simulations used for LRT\n",
    "        obs_het_dic_lrt = {}\n",
    "        obs_comm_dic_lrt = {}\n",
    "        obs_bins_dic_lrt = {}\n",
    "    \n",
    "        # Fill in dictionaries of summary statistics\n",
    "        for s in s_vals:\n",
    "            \n",
    "            obs_het_dic[s] = []\n",
    "            obs_comm_dic[s] = []\n",
    "            obs_bins_dic[s] = []\n",
    "            \n",
    "            freqs_list_raw = GetLRTListFreq(lrtFile, s) # Get list of allele frequencies for this s\n",
    "            \n",
    "            # Get summary statistics from frequencies\n",
    "            for freq_string in freqs_list_raw:\n",
    "                \n",
    "                obs_het, obs_common, obs_bins = GetSummStats(freq_string, num_bins)\n",
    "                obs_het_dic[s].append(obs_het)\n",
    "                obs_comm_dic[s].append(obs_common)\n",
    "                obs_bins_dic[s].append(obs_bins)\n",
    "            \n",
    "        abcFile = '/gymreklab-tscc/bonnieh/abc/results/' + model +'/' + str(per) + '_' + str(opt_allele) + '.txt' \n",
    "\n",
    "        # Read abcFile line by line and place in lookup table in the form of a list\n",
    "        abc_list = GetABCList(abcFile, num_bins)\n",
    "        \n",
    "        # Perform ABC\n",
    "        for s in s_vals:\n",
    "            \n",
    "            list_est_s = [] # List of posterior estimates of s\n",
    "            # Lists of summary statistics of s\n",
    "            list_het = []\n",
    "            list_common = []\n",
    "            list_bins = []\n",
    "            \n",
    "            for i in range(0, len(obs_het_dic[s])):\n",
    "                obs_het  = float(obs_het_dic[s][i])\n",
    "                obs_common = int(obs_comm_dic[s][i])\n",
    "                obs_bins = obs_bins_dic[s][i]\n",
    "                \n",
    "                s_ABC, lower_bound, upper_bound, num_accepted, s_accepted = Get_S_ABC(abc_list, \\\n",
    "                                       obs_het, obs_common, obs_bins, constant_het, \\\n",
    "                                       denom_het, constant_common, denom_common, eps_bins, use_het, \\\n",
    "                                       use_common, use_bins)\n",
    "                if s_ABC != -1:\n",
    "        \n",
    "                    s_ABC_round = get_LRT_bin(s_ABC)\n",
    "            \n",
    "                    # Get nearest s in LRT file to perform LRT\n",
    "                    if s_ABC_round not in s_list_available:\n",
    "                        #print('Not available: per %d opt allele %d s_ABC_round %.5f'%(per, opt_allele, s_ABC_round))\n",
    "                        s_ABC_round = getNearestS(s_ABC_round, s_list_available)\n",
    "                        #print('Nearest s: %.5f'%(s_ABC_round))\n",
    "                    list_est_s.append(s_ABC_round) \n",
    "                    list_het.append(obs_het)\n",
    "                    list_common.append(obs_common)\n",
    "                    list_bins.append(obs_bins)\n",
    "                else:\n",
    "                    no_ABC_accept = no_ABC_accept + 1\n",
    "                    \n",
    "            est_s_dic[s] = list_est_s\n",
    "            obs_het_dic_lrt[s] = list_het\n",
    "            obs_comm_dic_lrt[s] = list_common\n",
    "            obs_bins_dic_lrt[s] = list_bins\n",
    "            #print(s)\n",
    "            #print(list_est_s)\n",
    "            \n",
    "            # Put mean of esimated s in s_vals_dic and calculate standard error of the mean\n",
    "            s_vals_dic[opt_allele].append(np.mean(list_est_s)) \n",
    "            std_err = stats.sem(list_est_s, ddof=0)\n",
    "            errors_s_dic[opt_allele].append(std_err)\n",
    "            \n",
    "        # Get LRT summary statistic tables for s = 0\n",
    "        freqs_list_raw_0 = GetLRTListFreq(lrtFile, 0)\n",
    "        LRT_table_0_het = []\n",
    "        LRT_table_0_common = []\n",
    "        LRT_table_0_bins = []\n",
    "        \n",
    "        # Get summary statistics from allele frequencies\n",
    "        for freq_string in freqs_list_raw_0:\n",
    "                \n",
    "            obs_het, obs_common, obs_bins = GetSummStats(freq_string, num_bins)\n",
    "            LRT_table_0_het.append(obs_het) \n",
    "            LRT_table_0_common.append(obs_common) \n",
    "            LRT_table_0_bins.append(obs_bins)\n",
    "                \n",
    "        # Perform LRT\n",
    "        for s in est_s_dic:\n",
    "            p_vals_list = []\n",
    "            obs_het_list = obs_het_dic_lrt[s]\n",
    "            obs_common_list = obs_comm_dic_lrt[s]\n",
    "            obs_bins_list = obs_bins_dic_lrt[s]\n",
    "            s_ABC_list = est_s_dic[s]\n",
    "            \n",
    "            for i in range(0, len(obs_het_list)):\n",
    "                obs_het = obs_het_list[i]\n",
    "                obs_common = obs_common_list[i]\n",
    "                obs_bins = obs_bins_list[i]\n",
    "                s_ABC_round = s_ABC_list[i]\n",
    "                \n",
    "                ### Use commented code if didn't round during ABC ###\n",
    "                '''\n",
    "                s_ABC_round = get_LRT_bin(s_ABC_round)\n",
    "                if s_ABC_round not in s_list_available:\n",
    "                    s_ABC_round = getNearestS(s_ABC_round, s_list_available)\n",
    "                '''\n",
    "                \n",
    "                # Get LRT summary statistic tables for s = s_ABC_round\n",
    "                freqs_list_raw_s = GetLRTListFreq(lrtFile, s_ABC_round)\n",
    "            \n",
    "                LRT_table_s_het = []\n",
    "                LRT_table_s_common = []\n",
    "                LRT_table_s_bins = []\n",
    "                \n",
    "                # Get summary statistics from allele frequencies\n",
    "                for freq_string in freqs_list_raw_s:\n",
    "                    \n",
    "                    obs_het, obs_common, obs_bins = GetSummStats(freq_string, num_bins)\n",
    "                    LRT_table_s_het.append(obs_het) \n",
    "                    LRT_table_s_common.append(obs_common) \n",
    "                    LRT_table_s_bins.append(obs_bins)\n",
    "                \n",
    "                if len(LRT_table_s_het) != 0:\n",
    "                    likelihood_0, likelihood_s_ABC, LR, LogLR, pval = LikelihoodRatioTest(LRT_table_0_het, LRT_table_s_het, \\\n",
    "                                LRT_table_0_common, LRT_table_s_common, LRT_table_0_bins, LRT_table_s_bins, LRT_num_sims, \\\n",
    "                                obs_het, obs_common, obs_bins, constant_het, denom_het, \\\n",
    "                                constant_common, denom_common, eps_bins, use_het, use_common, use_bins)\n",
    "                \n",
    "                    p_vals_list.append(pval) # -1*np.log10(pval)\n",
    "                \n",
    "            # Put mean of esimated p in p_vals_dic and calculate standard error of the mean\n",
    "            #print(s)\n",
    "            #print(p_vals_list)\n",
    "            p_vals_dic[opt_allele].append(len([i for i in p_vals_list if i < 0.05])/len(p_vals_list)*100) # np.mean(p_vals_list)\n",
    "            std_err = stats.sem(p_vals_list, ddof = 0)\n",
    "            errors_p_dic[opt_allele].append(std_err)\n",
    "            \n",
    "            #print(no_ABC_accept)\n",
    "          \n",
    "    # Plot ABC and LRT validation graphs\n",
    "    fig_num = fig_num + 1\n",
    "    plot_figure(fig_num, per, opt_allele_list, s_vals_dic, errors_s_dic, s_vals, use_het, use_common, use_bins, num_bins, eps_bins, model, 'abc')\n",
    "    fig_num = fig_num + 1\n",
    "    plot_figure(fig_num, per, opt_allele_list, p_vals_dic, errors_p_dic, s_vals, use_het, use_common, use_bins, num_bins, eps_bins, model, 'lrt')\n",
    "    return fig_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('Running main')\n",
    "    \n",
    "    #per_list = [2,3,4]\n",
    "    per_list = [2,3,4] # List of periods to validate\n",
    "    \n",
    "    opt_alleles = {} # Key: period, Value: list of optimal alleles to validate\n",
    "    opt_alleles[2] = '11,14,17,20'\n",
    "    opt_alleles[3] = '6,8,10,12'\n",
    "    #opt_alleles[3] = '5,6,7,8,9,10,11,12'\n",
    "    opt_alleles[4] = '7,8,9,10'\n",
    "    \n",
    "    s_vals = '0.000001,0.00001,0.0001,0.001,0.004,0.007,0.01,0.04,0.07,0.1,0.15,0.2' # S values to validate\n",
    "    #s_vals = '0.000001,0.0001,0.01'\n",
    "   \n",
    "    # Summary statistics to use\n",
    "    use_het = 'y'\n",
    "    use_common = 'n'\n",
    "    use_bin = 'y'\n",
    "    \n",
    "    #num_bins_list = [3,5,7] # Number of bins to use for validation\n",
    "    num_bins_list = [5]\n",
    "    \n",
    "    #model_list = ['euro_p1', 'euro_p2']\n",
    "    model_list = ['euro_p2'] # Prior to use\n",
    "    fig_num = 0\n",
    "    \n",
    "    # Run validation\n",
    "    for per in per_list:\n",
    "        for num_bins in num_bins_list:\n",
    "            for model in model_list:\n",
    "                fig_num = validate(per, opt_alleles[per], s_vals, use_het, use_common, use_bin, num_bins, model, fig_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running main\n",
      "Running per: 2 optimal allele: 11\n",
      "Running per: 2 optimal allele: 14\n",
      "Running per: 2 optimal allele: 17\n",
      "Running per: 2 optimal allele: 20\n",
      "Done figure 1\n",
      "Done figure 2\n",
      "Running per: 3 optimal allele: 6\n",
      "Running per: 3 optimal allele: 8\n",
      "Running per: 3 optimal allele: 10\n",
      "Running per: 3 optimal allele: 12\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
