{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "'''Plot qq plot to compare distribution of LogLR values\n",
    "with the chisq (df=1) distribution.'''\n",
    "\n",
    "%pylab inline\n",
    "import sys\n",
    "sys.path.append(\"/storage/BonnieH/selection_project/helper_functions\")\n",
    "from LRT_functions import *\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import time\n",
    "PLOTDIR = '/storage/BonnieH/selection_project/validation_per_locus/figures/qq_plot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot QQ plot\n",
    "def plot_figure(fig_num, per, opt_allele_list, LogLR_vals_dic, p_vals_dic, abc_model):\n",
    "    \n",
    "    # Get minimum length of all LogLR lists\n",
    "    min_length = 500\n",
    "    for opt_allele in opt_allele_list:\n",
    "        length = len(LogLR_vals_dic[opt_allele])\n",
    "        if length < min_length:\n",
    "            min_length = length\n",
    "    \n",
    "    for opt_allele in opt_allele_list:\n",
    "        LogLR_list = LogLR_vals_dic[opt_allele]\n",
    "        \n",
    "        # Plot histogram of LogLR values\n",
    "        fig_num = fig_num + 1\n",
    "        plt.figure(fig_num)\n",
    "        plt.hist(LogLR_list, bins = 20, weights=np.ones(len(LogLR_list)) / len(LogLR_list)) \n",
    "        plt.title('Plot of LogLR values \\n Per %d Opt %d'%(per, opt_allele))\n",
    "        plt.xlabel('LogLR value')\n",
    "        plt.ylabel('Fraction of values')\n",
    "        plt.savefig(PLOTDIR + 'LogLR/LogLR_per_%d_opt_%d'%(per,opt_allele), bbox_inches='tight')\n",
    "        \n",
    "        # Plot histogram of LogLR values where negative values are set to 0\n",
    "        fig_num = fig_num + 1\n",
    "        plt.figure(fig_num)\n",
    "        LogLR_list_no_neg = [0 if i < 0 else i for i in LogLR_list] \n",
    "        LogLR_list_no_neg.sort()\n",
    "        plt.hist(LogLR_list_no_neg, bins = 20, weights=np.ones(len(LogLR_list_no_neg)) / len(LogLR_list_no_neg)) \n",
    "        plt.title('Plot of LogLR values (setting negative values to 0) \\n Per %d Opt %d'%(per, opt_allele))\n",
    "        plt.xlabel('LogLR value')\n",
    "        plt.ylabel('Fraction of values')\n",
    "        plt.savefig(PLOTDIR + 'LogLR/LogLR_no_neg_per_%d_opt_%d'%(per,opt_allele), bbox_inches='tight')\n",
    "        \n",
    "    # Plot Chi-square distribution\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    \n",
    "    exp_list = []\n",
    "    for i in range(0, min_length):\n",
    "        LogLR = np.random.chisquare(1)\n",
    "        exp_list.append(float(LogLR))\n",
    "    exp_list.sort()\n",
    "    plt.hist(exp_list, bins = 20, weights=np.ones(len(exp_list)) / len(exp_list), color='green') #weights=np.ones(exp_list) / len(exp_list))\n",
    "    plt.title('Plot of chisq (df=1) distribution')\n",
    "    plt.savefig(PLOTDIR + 'Chisq/Chisq_for_per_%d'%(per), bbox_inches='tight')\n",
    "        \n",
    "    # Plot QQ plot LogLR v chisq distribution\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    x_max = max(exp_list)\n",
    "    for opt_allele in opt_allele_list:\n",
    "        LogLR_list = LogLR_vals_dic[opt_allele][0:min_length]\n",
    "        LogLR_list_no_neg = [0 if i < 0 else i for i in LogLR_list] \n",
    "        LogLR_list_no_neg.sort()\n",
    "        plt.scatter(exp_list, LogLR_list_no_neg, s=5, label=str(opt_allele)) \n",
    "    \n",
    "        x_max_observed = max(LogLR_list_no_neg)\n",
    "        if x_max_observed > x_max:\n",
    "            x_max = x_max_observed\n",
    "    plt.plot([0,x_max],[0,x_max],c='black')\n",
    "    \n",
    "    plt.title('LogLR v chisq (df=1) distribution \\n Per %d'%(per))\n",
    "    plt.xlabel(\"Expected LogLR (chisq df=1)\")\n",
    "    plt.ylabel(\"Observed LogLR\")\n",
    "    plt.legend()\n",
    "    plt.savefig(PLOTDIR + 'qq_LogLR/qq_LogLR_per_%d'%(per), bbox_inches='tight')\n",
    "     \n",
    "    # Plot QQ plot of p values of LogLR v chisq distribution\n",
    "    fig_num = fig_num + 1\n",
    "    plt.figure(fig_num)\n",
    "    \n",
    "    p_val_exp = []\n",
    "    for elem in exp_list:\n",
    "        pval = chi2.sf(elem, 1) \n",
    "        p_val_exp.append(-np.log10(pval))\n",
    "    x_max = max(p_val_exp)\n",
    "    p_val_exp.sort()\n",
    "    \n",
    "    for opt_allele in opt_allele_list:\n",
    "        p_val_obs = p_vals_dic[opt_allele][0:min_length]\n",
    "        \n",
    "        p_val_obs.sort()\n",
    "        \n",
    "        plt.scatter(p_val_exp, p_val_obs, s=5, label=str(opt_allele)) # color=\"black\", label='coding')\n",
    "    \n",
    "        x_max_observed = max(p_val_obs)\n",
    "       \n",
    "        if x_max_observed > x_max:\n",
    "            x_max = x_max_observed\n",
    "    \n",
    "    plt.plot( [0,x_max],[0, x_max],c='black' )\n",
    "    plt.title('LogLR v chisq (df=1) -log10(p) distribution \\n Per %d'%(per))\n",
    "    plt.xlabel(\"Expected -log10(p) (chisq df=1)\")\n",
    "    plt.ylabel(\"Observed -log10(p)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(PLOTDIR + 'qq_p_val/qq_p_val_per_%d'%(per), bbox_inches='tight')\n",
    "\n",
    "    print('Done figure ' + str(fig_num))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate ABC and LRT\n",
    "def validate(per, opt_allele, s_vals, use_het, use_common, use_bins, num_bins, abc_model, lrt_model, fig_num):\n",
    "    \n",
    "    # Process list of optimal alleles\n",
    "    opt_allele_list = list(opt_allele.split(','))\n",
    "    opt_allele_list = list(map(int, opt_allele_list)) \n",
    "    \n",
    "    # Process list of s values\n",
    "    s_vals = list(s_vals.split(','))\n",
    "    s_vals = list(map(float, s_vals))\n",
    "    \n",
    "    # ABC parameters\n",
    "    constant_het = 0.005\n",
    "    denom_het = 3\n",
    "    constant_common = 1\n",
    "    denom_common = 4\n",
    "    eps_bins = 0.3\n",
    "    \n",
    "    # LRT parameters\n",
    "    LRT_num_sims = 200\n",
    "         \n",
    "    # Each dictionary contains values for all optimal alleles\n",
    "    # Key: optimal allele\n",
    "    # Value: list of mean values for each s \n",
    "    s_vals_dic = {}\n",
    "    p_vals_dic = {}\n",
    "    LogLR_vals_dic = {}\n",
    "    \n",
    "    # Initialize dictionaries above\n",
    "    for opt_allele in opt_allele_list:\n",
    "        s_vals_dic[opt_allele] = []\n",
    "        p_vals_dic[opt_allele] = []\n",
    "        LogLR_vals_dic[opt_allele] = []\n",
    "      \n",
    "    # Run ABC and LRT for each opt_allele\n",
    "    for opt_allele in opt_allele_list:\n",
    "        LogLR_list = []\n",
    "        l0_list = []\n",
    "        ls_list = []\n",
    "        print('Running per: ' + str(per) + ' optimal allele: ' + str(opt_allele))\n",
    "        no_ABC_accept = 0 # Number of s values with <10 ABC acceptances\n",
    "        \n",
    "        ### Get list of s values in LRT simulations file ###\n",
    "        s_list_available = []\n",
    "        lrtFile = '/gymreklab-tscc/bonnieh/lrt/results/' + lrt_model + '/' + str(per) + '_' + str(opt_allele) + '_freqs.txt' # euro_prelim #const_prelim\n",
    "        lrt_file = open(lrtFile, 'r')\n",
    "        header = lrt_file.readline().strip()\n",
    "    \n",
    "        for line in lrt_file:\n",
    "            info = line.strip().split('\\t')\n",
    "            s = float(info[0])\n",
    "            if s not in s_list_available:\n",
    "                s_list_available.append(s)\n",
    "            \n",
    "        est_s_dic = {} # Dictionary of estimated s values; Key: True value of s, Value: list of estimated s values\n",
    "        \n",
    "        # Put summary statistics in dictionaries\n",
    "        obs_het_dic = {} # Key - s; value - list of het\n",
    "        obs_comm_dic = {} # Key - s; value - list of number of common alleles (frequency >= 5%)\n",
    "        obs_bins_dic = {} # Key - s; value - list of bins (bins are given as lists)\n",
    "        \n",
    "        # Same as dictionaries above except without simulations \n",
    "        # where s could not be estimated using ABC (<10 ABC acceptances)\n",
    "        # These are the simulations used for LRT\n",
    "        obs_het_dic_lrt = {}\n",
    "        obs_comm_dic_lrt = {}\n",
    "        obs_bins_dic_lrt = {}\n",
    "    \n",
    "        # Fill in dictionaries of summary statistics\n",
    "        for s in s_vals:\n",
    "            \n",
    "            obs_het_dic[s] = []\n",
    "            obs_comm_dic[s] = []\n",
    "            obs_bins_dic[s] = []\n",
    "            \n",
    "            freqs_list_raw = GetLRTListFreq(lrtFile, s) # Get list of allele frequencies for this s\n",
    "            \n",
    "            # Get summary statistics from frequencies\n",
    "            for freq_string in freqs_list_raw:\n",
    "                \n",
    "                obs_het, obs_common, obs_bins = GetSummStats(freq_string, num_bins)\n",
    "                obs_het_dic[s].append(obs_het)\n",
    "                obs_comm_dic[s].append(obs_common)\n",
    "                obs_bins_dic[s].append(obs_bins)\n",
    "            \n",
    "        abcFile = '/gymreklab-tscc/bonnieh/abc/results/' + abc_model +'/' + str(per) + '_' + str(opt_allele) + '.txt' \n",
    "\n",
    "        # Read abcFile line by line and place in lookup table in the form of a list\n",
    "        abc_list = GetABCList(abcFile, num_bins)\n",
    "        \n",
    "        # Perform ABC\n",
    "        for s in s_vals:\n",
    "            \n",
    "            list_est_s = [] # List of posterior estimates of s\n",
    "            \n",
    "            # Lists of summary statistics of s\n",
    "            list_het = []\n",
    "            list_common = []\n",
    "            list_bins = []\n",
    "            \n",
    "            for i in range(0, len(obs_het_dic[s])):\n",
    "                obs_het  = float(obs_het_dic[s][i])\n",
    "                obs_common = int(obs_comm_dic[s][i])\n",
    "                obs_bins = obs_bins_dic[s][i]\n",
    "                \n",
    "                s_ABC, lower_bound, upper_bound, num_accepted, s_accepted = Get_S_ABC(abc_list, \\\n",
    "                                       obs_het, obs_common, obs_bins, constant_het, \\\n",
    "                                       denom_het, constant_common, denom_common, eps_bins, use_het, \\\n",
    "                                       use_common, use_bins)\n",
    "                if s_ABC != -1:\n",
    "        \n",
    "                    s_ABC_round = get_LRT_bin(s_ABC)\n",
    "            \n",
    "                    # Get nearest s in LRT file to perform LRT\n",
    "                    if s_ABC_round not in s_list_available:\n",
    "                        #print('Not available: per %d opt allele %d s_ABC_round %.5f'%(per, opt_allele, s_ABC_round))\n",
    "                        s_ABC_round = getNearestS(s_ABC_round, s_list_available)\n",
    "                        #print('Nearest s: %.5f'%(s_ABC_round))\n",
    "                    list_est_s.append(s_ABC_round) \n",
    "                    list_het.append(obs_het)\n",
    "                    list_common.append(obs_common)\n",
    "                    list_bins.append(obs_bins)\n",
    "                else:\n",
    "                    no_ABC_accept = no_ABC_accept + 1\n",
    "                    print(no_ABC_accept)\n",
    "                    \n",
    "            est_s_dic[s] = list_est_s\n",
    "            obs_het_dic_lrt[s] = list_het\n",
    "            obs_comm_dic_lrt[s] = list_common\n",
    "            obs_bins_dic_lrt[s] = list_bins\n",
    "            \n",
    "            # Put mean of esimated s in s_vals_dic \n",
    "            s_vals_dic[opt_allele].append(np.mean(list_est_s)) \n",
    "            \n",
    "        # Get LRT summary statistic tables for s = 0\n",
    "        lrtFile_for_s_0 = '/gymreklab-tscc/bonnieh/lrt/results/' + lrt_model[:-6] + '/' + str(per) + '_' + str(opt_allele) + '_15_freqs.txt' # euro_prelim #const_prelim\n",
    "        freqs_list_raw_0 = GetLRTListByRow(lrtFile_for_s_0, 0)\n",
    "        #freqs_list_raw_0 = GetLRTListFreq(lrtFile, 0)\n",
    "        LRT_table_0_het = []\n",
    "        LRT_table_0_common = []\n",
    "        LRT_table_0_bins = []\n",
    "        \n",
    "        # Get summary statistics from allele frequencies\n",
    "        for freq_string in freqs_list_raw_0:\n",
    "                \n",
    "            obs_het, obs_common, obs_bins = GetSummStats(freq_string, num_bins)\n",
    "            LRT_table_0_het.append(obs_het) \n",
    "            LRT_table_0_common.append(obs_common) \n",
    "            LRT_table_0_bins.append(obs_bins)\n",
    "                \n",
    "        # Perform LRT\n",
    "        for s in est_s_dic:\n",
    "            p_vals_list = []\n",
    "            obs_het_list = obs_het_dic_lrt[s]\n",
    "            obs_common_list = obs_comm_dic_lrt[s]\n",
    "            obs_bins_list = obs_bins_dic_lrt[s]\n",
    "            s_ABC_list = est_s_dic[s]\n",
    "            \n",
    "            for i in range(0, len(obs_het_list)):\n",
    "                obs_het = obs_het_list[i]\n",
    "                obs_common = obs_common_list[i]\n",
    "                obs_bins = obs_bins_list[i]\n",
    "                s_ABC_round = s_ABC_list[i]\n",
    "                \n",
    "                ### Use commented code if didn't round during ABC ###\n",
    "                '''\n",
    "                s_ABC_round = get_LRT_bin(s_ABC_round)\n",
    "                if s_ABC_round not in s_list_available:\n",
    "                    s_ABC_round = getNearestS(s_ABC_round, s_list_available)\n",
    "                '''\n",
    "                \n",
    "                # Get LRT summary statistic tables for s = s_ABC_round\n",
    "                if s_ABC_round == 0:\n",
    "                    freqs_list_raw_s = GetLRTListByRow(lrtFile_for_s_0, 1)\n",
    "                else:\n",
    "                    freqs_list_raw_s = GetLRTListFreq(lrtFile, s_ABC_round)\n",
    "            \n",
    "                LRT_table_s_het = []\n",
    "                LRT_table_s_common = []\n",
    "                LRT_table_s_bins = []\n",
    "                \n",
    "                # Get summary statistics from allele frequencies\n",
    "                for freq_string in freqs_list_raw_s:\n",
    "                    \n",
    "                    obs_het_s_ABC, obs_common_s_ABC, obs_bins_s_ABC = GetSummStats(freq_string, num_bins)\n",
    "                    LRT_table_s_het.append(obs_het_s_ABC) \n",
    "                    LRT_table_s_common.append(obs_common_s_ABC) \n",
    "                    LRT_table_s_bins.append(obs_bins_s_ABC)\n",
    "                \n",
    "                if len(LRT_table_s_het) != 0:\n",
    "                    likelihood_0, likelihood_s_ABC, LR, LogLR, pval = LikelihoodRatioTest(LRT_table_0_het, LRT_table_s_het, \\\n",
    "                                LRT_table_0_common, LRT_table_s_common, LRT_table_0_bins, LRT_table_s_bins, LRT_num_sims, \\\n",
    "                                obs_het, obs_common, obs_bins, constant_het, denom_het, \\\n",
    "                                constant_common, denom_common, eps_bins, use_het, use_common, use_bins)\n",
    "                \n",
    "                    p_vals_list.append(-np.log10(pval))\n",
    "                    LogLR_list.append(LogLR)\n",
    "                    l0_list.append(likelihood_0)\n",
    "                    ls_list.append(likelihood_s_ABC)\n",
    "        \n",
    "            LogLR_vals_dic[opt_allele] = LogLR_list\n",
    "            \n",
    "            p_vals_dic[opt_allele] = p_vals_list\n",
    "          \n",
    "    # Plot QQ Plot\n",
    "    fig_num = fig_num + 1\n",
    "    plot_figure(fig_num, per, opt_allele_list, LogLR_vals_dic, p_vals_dic, abc_model)\n",
    "    #fig_num = fig_num + 1\n",
    "    #plot_figure(fig_num, per, opt_allele_list, p_vals_dic, errors_p_dic, s_vals, use_het, use_common, use_bins, num_bins, eps_bins, abc_model, 'lrt')\n",
    "    return fig_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('Running main')\n",
    "    \n",
    "    # List of periods to show distribution of LogLR \n",
    "    per_list = [4] \n",
    "    \n",
    "    # Dictionary of optimal alleles \n",
    "    # Key: period, Value: string of optimal alleles to validate separated by commas\n",
    "    opt_alleles = {}\n",
    "    opt_alleles[1] = '16,24,32,40'\n",
    "    opt_alleles[2] = '11,14,17,20'\n",
    "    opt_alleles[3] = '6,8,10,12'\n",
    "    #opt_alleles[3] = '5,6,7,8,9,10,11,12'\n",
    "    opt_alleles[4] = '7,8,9,10'\n",
    "    \n",
    "    s_vals = '0'\n",
    "    \n",
    "    # Summary statistics to use - 'y' = yes, 'n' = no\n",
    "    use_het = 'y'\n",
    "    use_common = 'n'\n",
    "    use_bin = 'y'\n",
    "    \n",
    "    #num_bins_list = [3,5,7] # Number of bins to use for validation\n",
    "    num_bins_list = [5]\n",
    "    \n",
    "    # Priors to use \n",
    "    model_list = [('eurodem_p2','eurodem_merge')] \n",
    "    fig_num = 0\n",
    "    \n",
    "    # Run validation\n",
    "    for per in per_list:\n",
    "        for num_bins in num_bins_list:\n",
    "            for model in model_list:\n",
    "                fig_num = validate(per, opt_alleles[per], s_vals, use_het, use_common, use_bin, num_bins, model[0], model[1], fig_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running main\n",
      "Running per: 4 optimal allele: 7\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
